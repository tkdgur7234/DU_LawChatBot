{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "369affe8-4e78-449a-b5fd-2e9e78e08eb0",
   "metadata": {},
   "source": [
    "# 1. GPU 확인\n",
    "- 현재 버전에서는 tesla T4 x 2 개의 GPU 로 학습하도록 설정하였습니다.\n",
    "- tesla T4 x 1 로 학습 가능합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c4b0de1-7000-45b5-8338-2f595866615a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Dec 11 03:24:12 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 510.108.03   Driver Version: 510.108.03   CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:3B:00.0 Off |                    0 |\n",
      "| N/A   36C    P0    26W /  70W |   1683MiB / 15360MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla T4            Off  | 00000000:5E:00.0 Off |                    0 |\n",
      "| N/A   53C    P0    55W /  70W |   2872MiB / 15360MiB |     50%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla T4            Off  | 00000000:AF:00.0 Off |                    0 |\n",
      "| N/A   27C    P8    14W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla T4            Off  | 00000000:D8:00.0 Off |                    0 |\n",
      "| N/A   59C    P0    68W /  70W |   7295MiB / 15360MiB |     96%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import logging\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"]=\"false\"\n",
    "os.environ['TRANSFORMERS_NO_ADVISORY_WARNINGS']='true'\n",
    "\n",
    "logging.disable(logging.INFO) \n",
    "logging.disable(logging.WARNING)\n",
    "\n",
    "model_name = 'gogamza/kobart-base-v2'\n",
    "\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5f49b1-81c7-4e07-8644-923da5b1d867",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2a049a-12ed-4624-ba70-7e8e153500ba",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114dfa8f-9c58-453c-abf2-899ae5dfabbc",
   "metadata": {},
   "source": [
    "# 2. 데이터 로드\n",
    "\n",
    "- Json 학습데이터에서 요약 Task 에 필요한 데이터만 로드\n",
    "- 원문 - 요약문 데이터 쌍 마다 저장하고, 데이터에 아이디를 부여"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "561678ce-dad1-4d22-8efe-9044360e40c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def load_json_from_dir(dir_path):\n",
    "    json_files = glob.glob(os.path.join(dir_path, '**/*.json'))\n",
    "    json_data = []\n",
    "    for file in json_files:\n",
    "        try:\n",
    "            with open(file, 'r', encoding='utf-8-sig') as f:\n",
    "                temp_json = json.load(f)\n",
    "                doc_id = str(temp_json['info']['id'])\n",
    "                json_data.append(\n",
    "                    {\n",
    "                        'id': doc_id,\n",
    "                        'summ_contxt': temp_json['Summary'][0]['summ_contxt'],\n",
    "                        'summ_pass': temp_json['Summary'][0]['summ_pass'],\n",
    "                    }\n",
    "                )\n",
    "        except Exception as e:\n",
    "            print(file, e)\n",
    "    return json_data\n",
    "    \n",
    "# test = load_json_from_dir('data/nia/1.Training/')\n",
    "# print(len(test))\n",
    "# test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17e67865-243a-40bf-b904-93e4ffa1ef1d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data size: 48084\n",
      "val   data size: 6010\n",
      "test  data size: 6011\n",
      "{'id': '41018258', 'summ_contxt': '함정수사라 함은 본래 범의를 가지지 아니한 자에 대하여 수사기관이 사술이나 계략 등을 써서 범의를 유발케 하여 범죄인을 검거하는 수사방법을 말하는 것이므로, 범의를 가진 자에 대하여 범행의 기회를 주거나 범행을 용이하게 한 것에 불과한 경우에는 함정수사라고 말할 수 없다(당원 1983. 4. 12. 선고 82도2433 판결 참조).', 'summ_pass': '범의를 가진 자에 대하여 범행의 기회를 주거나 범행을 용이하게 한 것에 불과한 경우에는 함정수사라고 말할 수 없다.'}\n"
     ]
    }
   ],
   "source": [
    "raw_train_json = load_json_from_dir('data/1.Training/')\n",
    "raw_validation_json = load_json_from_dir('data/2.Validation/')\n",
    "raw_test_json = load_json_from_dir('data/3.Test/')\n",
    "\n",
    "print('train data size:', len(raw_train_json))\n",
    "print('val   data size:', len(raw_validation_json))\n",
    "print('test  data size:', len(raw_test_json))\n",
    "print(raw_test_json[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6d261d-4e22-4b09-85e6-7a9e26a87f2b",
   "metadata": {},
   "source": [
    "## 2-1. 데이터 샘플"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63fbac3d-7436-4856-893e-ccb829b9ca73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '42016558',\n",
       " 'summ_contxt': '누구든지 정당의 후보자추천 관련 금품을 수수하지 못하도록 금지한 공직선거법 제47조의2 제1항에서 ‘후보자로 추천하는 일과 관련하여’란, 금품의 제공이 후보자 추천의 대가 또는 사례에 해당하거나 그렇지 않다 하더라도 후보자 추천에 관하여 그러한 금품의 제공이 어떠한 형태로든 영향을 미칠 수 있는 경우에 해당하는 것을 의미한다(대법원 2009. 4. 23. 선고 2009도834 판결). 또한 국회의원 선거에서 정당의 공천을 받게 하여 줄 의사나 능력이 없음에도 이를 해 줄 수 있는 것처럼 기망하여 공천과 관련하여 금품을 받은 경우 공직선거법상 공천 관련 금품 수수죄와 사기죄가 모두 성립하고 양자는 상상적 경합의 관계에 있다(대법원 2009. 4. 23. 선고 2009도834 판결 참조).\\n\\n원심판결 이유를 위 법리 및 적법하게 채택된 증거들에 비추어 살펴보면, 원심의 이러한 판단에 상고이유 주장과 같이 논리와 경험의 법칙을 위반하여 자유심증주의의 한계를 벗어나거나 위 공직선거법 규정 위반죄의 주체와 구성요건 및 사기죄와의 관계 등에 관한 법리를 오해하고 필요한 심리를 다하지 아니하여 판결에 영향을 미친 위법이 없다.',\n",
       " 'summ_pass': '원심판결 이유를 위 법리 및 적법하게 채택된 증거들에 비추어 살펴보면, 원심의 이러한 판단에 상고이유 주장과 같이 논리와 경험의 법칙을 위반하여 자유심증주의의 한계를 벗어나거나 위 공직선거법 규정 위반죄의 주체와 구성요건 및 사기죄와의 관계 등에 관한 법리를 오해하고 필요한 심리를 다하지 아니하여 판결에 영향을 미친 위법이 없다.'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_train_json[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c789c94-9426-4426-966d-54acd9bb6aaf",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b53ea38-4f11-4234-8083-b4e6b79a3883",
   "metadata": {},
   "source": [
    "# 3. 학습데이터 전처리\n",
    "\n",
    "- 요약 Task를 위한 BART 모델을 불러오고,\n",
    "- Tokenizer 를 통해 BART 모델의 max_seq 값을 넘는 데이터는 제외하도록 처리\n",
    "- 요약 Task 에 불필요한 TAG, ()괄호안의 내용도 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "269b06c8-24d2-4a16-b8bf-78cf23640bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import tqdm\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "\n",
    "\n",
    "def preprocessing(list_of_dict_data):\n",
    "    data_trimmed = []\n",
    "    for data in list_of_dict_data:\n",
    "        # if len(tokenizer(data['summ_contxt'])['input_ids']) < 20 or len(tokenizer(data['summ_pass'])['input_ids']) < 20:\n",
    "        #     continue\n",
    "        # if len(tokenizer(data['summ_contxt'])['input_ids']) > 1024 or len(tokenizer(data['summ_pass'])['input_ids']) > 1024:\n",
    "        #     continue\n",
    "        # if len(tokenizer(data['summ_contxt'])['input_ids']) is None or  len(tokenizer(data['summ_pass'])['input_ids']) == 0:\n",
    "        #     continue\n",
    "        # if len(tokenizer(data['summ_contxt'])['input_ids']) is None or len(tokenizer(data['summ_pass'])['input_ids']) == 0:\n",
    "        #     continue\n",
    "            \n",
    "        data['summ_contxt'] = data['summ_contxt'].replace('_x000D_', '').replace('\\r', '').replace('\\n', ' ').strip()\n",
    "        data['summ_pass'] = data['summ_pass'].replace('_x000D_', '').replace('\\r', '').replace('\\n', ' ').strip()\n",
    "        data_trimmed.append(data)\n",
    "    return data_trimmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca297485-8114-4376-bf06-f8f6e1cd143b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data size: 48084\n",
      "val   data size: 6010\n",
      "test  data size: 6011\n"
     ]
    }
   ],
   "source": [
    "raw_train_data = preprocessing(raw_train_json)\n",
    "raw_validation_data = preprocessing(raw_validation_json)\n",
    "raw_test_data = preprocessing(raw_test_json)\n",
    "\n",
    "print('train data size:', len(raw_train_data))\n",
    "print('val   data size:', len(raw_validation_data))\n",
    "print('test  data size:', len(raw_test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98c452c-b7c2-4c76-80b9-5acbf160dbdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc133900-5b3c-4b50-ad6b-7b2a1aadaeb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba4ff3d-cec9-43b6-afa5-e96a7776b601",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "892f6283-68cb-4311-97b2-bc6fe0e98599",
   "metadata": {},
   "source": [
    "## 3-1. 전처리후 데이터 샘플"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fad23bce-4dbf-4397-8a43-6d1d572b9b12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '41018258',\n",
       " 'summ_contxt': '함정수사라 함은 본래 범의를 가지지 아니한 자에 대하여 수사기관이 사술이나 계략 등을 써서 범의를 유발케 하여 범죄인을 검거하는 수사방법을 말하는 것이므로, 범의를 가진 자에 대하여 범행의 기회를 주거나 범행을 용이하게 한 것에 불과한 경우에는 함정수사라고 말할 수 없다(당원 1983. 4. 12. 선고 82도2433 판결 참조).',\n",
       " 'summ_pass': '범의를 가진 자에 대하여 범행의 기회를 주거나 범행을 용이하게 한 것에 불과한 경우에는 함정수사라고 말할 수 없다.'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_test_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f94985-a4ea-400f-8bcc-1bb7e4d50247",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b303ec24-26a2-470b-b727-afd85c0a1b98",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a03579-de97-4191-8f8d-66fbf6840101",
   "metadata": {},
   "source": [
    "# 4. 학습데이터 빌드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c5f0ba6d-0760-42ce-b370-835b6b7f7572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습/테스트 데이터의 구성: \n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'summ_contxt', 'summ_pass'],\n",
      "        num_rows: 48084\n",
      "    })\n",
      "    val: Dataset({\n",
      "        features: ['id', 'summ_contxt', 'summ_pass'],\n",
      "        num_rows: 6010\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'summ_contxt', 'summ_pass'],\n",
      "        num_rows: 6011\n",
      "    })\n",
      "})\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d4c0d8645154c5596d6e1cf676ce823",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/48084 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bdbae80a5594a5786b1fa3e06694c75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6010 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e5d9db86d66418e81096a867280d636",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6011 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from datasets.dataset_dict import DatasetDict\n",
    "from datasets import Dataset\n",
    "\n",
    "raw_train_set = Dataset.from_list(raw_train_data)\n",
    "raw_valid_set = Dataset.from_list(raw_validation_data)\n",
    "raw_test_set = Dataset.from_list(raw_test_data)\n",
    "raw_datasets = DatasetDict(\n",
    "    {\n",
    "        'train': raw_train_set,\n",
    "        'val': raw_valid_set,\n",
    "        'test': raw_test_set\n",
    "    }\n",
    ")\n",
    "\n",
    "print('학습/테스트 데이터의 구성: ')\n",
    "print(raw_datasets)\n",
    "print()\n",
    "print()\n",
    "\n",
    "max_input_length = 1024\n",
    "max_target_length = 1024\n",
    "\n",
    "def data_build_function(examples):\n",
    "    tokenizer = PreTrainedTokenizerFast.from_pretrained(model_name)\n",
    "\n",
    "    inputs = [doc for doc in examples[\"summ_contxt\"]]\n",
    "    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True)\n",
    "    labels = tokenizer(text_target=[doc + '</s>' for doc in examples[\"summ_pass\"]], max_length=max_target_length, truncation=True)\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "tokenized_datasets = raw_datasets.map(data_build_function, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81787315-947e-49ef-b10e-0eb9cca98fb2",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7fc1c1-b14f-40dd-b112-ed792d3d77ec",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7d2fa8-5816-41aa-ac09-837d18bde7b9",
   "metadata": {},
   "source": [
    "# 5. 모델학습\n",
    "- batch size: 4,  epoch: 15\n",
    "- 매 epoch 마다 모델을 저장합니다. (save dir: /result/)\n",
    "- 모델저장 디렉토리를 변경하려면, training_args 에 'output_dir' 을 수정하면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bf841e04-1349-4684-8d69-8c0502040212",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d2ad68a74bb4d839bcb7751a00a72d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/495M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "from transformers import Seq2SeqTrainingArguments\n",
    "from transformers import Trainer, DataCollatorForSeq2Seq\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "from transformers import BartForConditionalGeneration\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=False, use_aggregator=False)\n",
    "    result = {key: value * 100 for key, value in result.items()}\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "    return {k: round(v, 4) for k, v in result.items()}\n",
    "\n",
    "\n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained(model_name)\n",
    "model = BartForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir='result/231210/', \n",
    "    logging_dir='logs/231210/',\n",
    "    evaluation_strategy=\"epoch\", \n",
    "    per_device_train_batch_size=4, \n",
    "    per_device_eval_batch_size=2,  \n",
    "    gradient_accumulation_steps=2,\n",
    "    learning_rate=1e-5,\n",
    "    weight_decay=1e-2,\n",
    "    adam_beta1=0.9,\n",
    "    adam_beta2=0.999,\n",
    "    adam_epsilon=1e-8,\n",
    "    max_grad_norm=1.0,\n",
    "    warmup_ratio=0.0,\n",
    "    num_train_epochs=10,\n",
    "    logging_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    fp16=True,\n",
    "    dataloader_num_workers=1,\n",
    "    disable_tqdm=False,\n",
    "    report_to=\"none\",\n",
    "    generation_max_length=1024,\n",
    "    generation_num_beams=512,\n",
    "    predict_with_generate=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model, \n",
    "    args=training_args, \n",
    "    data_collator=DataCollatorForSeq2Seq(tokenizer, model=model),\n",
    "    train_dataset=tokenized_datasets['train'], \n",
    "    eval_dataset=tokenized_datasets['val'],\n",
    "    # compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cccede0-690d-4fc3-89af-936f39d6879d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5087' max='60100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 5087/60100 20:02 < 3:36:46, 4.23 it/s, Epoch 0.85/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_result = trainer.train() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c611e7f9-f17b-4bb1-830c-c2a799f0b765",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "train_log = {\n",
    "    'train_output': {\n",
    "        'global_step': train_result.global_step, \n",
    "        'training_loss': train_result.training_loss, \n",
    "        'metrics': train_result.metrics\n",
    "    },\n",
    "    'train_runtime': str(datetime.timedelta(seconds=train_result.metrics['train_runtime'])),\n",
    "    'log_history': trainer.state.log_history\n",
    "}\n",
    "train_log = json.dumps(train_log, indent=2, ensure_ascii=False)\n",
    "print(train_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbdf1f5-d517-4775-a572-7e078947b80e",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## 5-1. Loss Plot\n",
    "- 학습과정의 validation loss 그래프를 나타냄.\n",
    "- validation loss 가 가장 낮은 모델의 checkpoint 를 이용해 모델 확정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a997d4-3daf-4239-8023-3c6f2737934e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_loss = []\n",
    "validation_loss = []\n",
    "for log in trainer.state.log_history:\n",
    "    if 'loss' in log.keys():\n",
    "        train_loss.append(log['loss'])\n",
    "    elif 'eval_loss' in log.keys():\n",
    "        validation_loss.append(log['eval_loss'])\n",
    "\n",
    "epochs = range(1, 10 + 1)\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(epochs, train_loss, 'b', label='Training loss')\n",
    "plt.plot(epochs, validation_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c074771-2e3e-4304-bf09-b08f58efea7e",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b545233e-5660-4aab-8d5f-e9e1fa6926e6",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b23fba-bdeb-450f-9195-faafe045712b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
